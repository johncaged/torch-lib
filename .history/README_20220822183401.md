# torch_lib

![License](https://img.shields.io/github/license/johncaged/torch-lib)
![PyPI](https://img.shields.io/pypi/v/torch_lib?color=blue)
![Stars](https://img.shields.io/github/stars/johncaged/torch-lib?color=ff69b4)

## 介绍

torch_lib 是一个基于深度学习框架 PyTorch 的开源训练库，对训练 pipeline 提供了一系列标准化的流程和预定义的接口，用于简化训练代码的编写，提高开发效率。

## 特性

### 快速构建

根据实际需要实现接口、配置参数，快速构建训练pipeline。

### 完全可定制化

torch_lib 使用组合模式构建一套标准的训练流程（具体详见xx部分）。除此之外，您还可以对这个流程进行自定义修改，灵活度相较于市面已有框架大幅度提高。

### 清晰可视化

torch_lib 支持清晰的控制台可视化功能，可以实现训练流程监控、模型结构预览等。

### 渐进式

torch_lib 与普通 PyTorch 代码完全兼容，您可以自由地使用 torch_lib 的部分实用工具或整个框架。

## 快速上手

此部分默认您已经熟悉 PyTorch 的基本训练流程。

### 模型与数据集

对于一个完整的 PyTorch 训练流程，模型和数据集的处理是必不可少的。在 torch_lib 中，此部分与 PyTorch 原生代码没有区别。


```python
from torch.nn import Module
from torch.utils.data import DataLoader

model: Module = Model()  # 标准PyTorch模型
dataset: DataLoader = DataLoader()  # 标准PyTorch数据集
```

### 开始训练

调用训练的过程分为三步：创建代理（Proxy）类、build 构建、train（eval、predict）。**此示例适用单输入单输出任务，即数据集的格式为（输入数据，标签），如果想要进行更复杂的任务构建，请阅读完此章节后继续阅读xx章节。**

#### 创建代理（Proxy）类

根据尽量使用关联而不是继承的原则，代理类只是对模型的一些行为进行调用，最大程度解耦合。

```python
from torch_lib import Proxy

# 此部分将 PyTorch 模型包裹起来，device 参数用于指定训练设备，当然也可以后续再进行设置。
proxy = Proxy(model, device='cpu')
```

#### build构建

使用 build 是为了方便进行一些通用不变的配置，比如评价指标（在训练、验证和测试的过程中往往使用相同的评价指标，因此只需要配置一次）。

```python
# 具体参数使用详见 API 文档。
proxy.build(
    loss=None,  # PyTorch 损失函数
    metrics=None,  # torch_lib 评价指标
    optimizer=None,  # PyTorch 优化器
    lr=None,  # 学习率
    lr_decay=None,  # 学习率衰减
    optimizer_options=None,
    lr_decay_options=None,
    data_parser=None  # 用于多输入多输出的数据转换器
)
```

训练流程必要的参数有损失函数和优化器，因此只需配置这两项即可开始训练。

```python
from torch.nn import CrossEntropyLoss
from torch.optim.adam import Adam

# 仅为示例，需要根据实际情况选择合适的损失函数和优化器。
proxy.build(
    loss=CrossEntropyLoss(),
    optimizer=Adam(model.parameters(), lr=1e-4)
)
```

#### 开始训练 / 评估 / 预测（train / eval / predict）

使用 build 配置好必要参数后，接下来就可以调用训练流程。此处仅以 train 为例。

```python
proxy.train(
    train_dataset=dataset,
    total_epochs=10
)
```

至此，torch_lib 配置和调用训练的基本流程就完成了。想要实现一些定制化流程和高级功能，可以继续阅读此文档的后续章节。

## 高级使用

想要熟练地使用 torch_lib 的高级功能，需要先理解 torch_lib 的一些核心概念。

### 核心概念

#### Core

##### /handler.py

###### 1. from abc import abstractmethod:
从abc模块导入抽象方法注释，可以用于对一个方法进行标注，从而不用过多关心方法本身的内容，只需要知道有这个方法即可，不需要实现。而在子类继承的时候实现它即可，用子类实例化即可调用子类的具体方法来执行相应操作。

###### 2. from typing import Dict, Sequence, Union: 
(1) Dict：dict的泛型(generic)版本，用于注解(annotate)返回类型。注解参数时，最好使用抽象集合类型(abstract collection type)，例如Mapping。Dict与dict之间没有真正的区别，但是Dict是泛型类型，它允许你指定key和value的类型，使其更加灵活。例如：
``` python
    def count_words(text: str)->Dict[str, int]: ...
    x: Dict[str, int] = {"Changsha", 1}
    print(x)
```

(2) Sequence: collections.abc.Sequence的泛型版本

(3) Union: 联合类型，Union[X, Y]等价于X|Y，意味着X或Y。使用形如Union[int, str]的形式来定义一个联合体：参数必须是某种类型，且至少有一个；联合类型的联合类型会被展开(flattened)；仅有一个参数的联合类型就是该参数自身；冗余的参数会被跳过(skipped)；在比较联合类型的时候，参数顺序会被忽略(ignored)；不能继承或者实例化一个联合类型；不支持Union[X][Y]这种写法。例如：
``` python
    # 联合类型的联合类型会被展开（flattened)
    Union[Union[int, str], float] == Union[int, str, float]
    # 仅有一个参数的联合类型就是该参数本身
    Union[int] = int
    # 冗余的参数会被跳过（skipped）
    Union[int, str, int] = Union[int, str]
    # 在比较联合类型的时候，参数顺序会被忽略（ignored）
    Union[int, str] == Union[str, int]
```

###### 3. from functools import wraps: 
由于函数本身也是一个对象，而且也可以赋值给别人，可以被调用。为了增强函数本身的功能，比如在函数调用前后做一些事情且不改变原有函数的定义，就需要用到装饰器。用装饰器去处理函数后，原函数的__name__等属性也会被装饰器的替代，所以需要用functools.wraps去处理，将原函数的属性再次替换回装饰器中。例如：
``` python
    import functools
    
    def log(text):
        def decorator(func):
            @functools.wraps(func)
            def wrapper(*args, **kw):
                print('%s %s():' % (text, func.__name__))
                return func(*args, **kw)
            return wrapper
        return decorator
```
比如写了一个函数：
``` python
>>> def loveyou()
...     print('2020-9-14')
```
则通过添加@log(‘execute’)的注释，可以使得输出变为下图，即在原本的打印前输出调用执行了的函数名：
``` python
execute loveyou()
2020-9-14
```
###### 4. def TorchGrad(func)：
是一个装饰器，用于在具体函数执行前，设置梯度计算模式的开闭。set_grad_enabled(mode)中的mode参数是一个布尔值，通过T或者F来控制开闭。通过获取上下文中TRAIN表示的对象中的状态，来设置是否需要梯度计算模式。所谓的梯度计算就是对向量的计算过程中产生的梯度进行保留，用于反向传播。
``` python
    def TorchGrad(func):
        """
        Set grad enabled or not according to the context mode.
        """
        @wraps(func)
        def grad_switch(self, ctx: Context):
            # only when context status is in ['TRAIN'] is the grad enabled
            with set_grad_enabled(str(ctx.status) in ['TRAIN']):
                func(self, ctx)
        return grad_switch
```
###### 5. 对于矩阵求导，现在的模型是这样的：
![pic1]()
则计算结果如下：
![pic2]()

###### 6. Handler类：
是所有处理器的基类，定义了一个__init__函数，一个抽象处理函数handle，以及一个__call__函数。其中__call__函数的作用是使类实例对象可以像调用普通函数那样，以“对象名()”的形式使用。例如：
``` python
    class Test:
        # 定义__call__方法
        def __call__(self, name, add):
            print("调用__call__方法", name, add)
    test = Test()
    test("Johncage", "Shark")
```

###### 7. EmptyHandler类：
是一个什么处理都不去做的处理器，继承自Handler，使用了InvocationDebug注释唤醒了Debug信息的输出。

###### 8. C_SEQ: 
是一个类型声明，可能是一个处理器，或者是一个由一系列处理器组成的序列。

###### 9. HandlerContainer类: 
处理器容器，采用了组合模式的设计理念，继承自Handler和BaseList，初始化时传入的handlers是C_SEQ类型的数据，通过BaseList的初始化确保生成一个列表。然后重载的handle函数将用自己内部包含的每一个处理器去对上下文进行处理。

###### 10. EpochIterationHandler类：
轮迭代处理器，继承自HandlerContainer，进行epoch.total次的操作，取每一轮，调用父类的handle方法，即把Container里每个处理器按顺序拿出来执行

###### 11. IterationHandler类：
步迭代处理器，继承自HandlerContainer，激活梯度计算模式，如果上下文中存在数据内容，就将向上下文的step中更新这一次的batch、progress等参数。

###### 12. ForwardHandler类：
前馈处理器，继承自HandlerContainer，将上下文中的数据解释后分别取出赋给x, y_true和extra，其中y_true作为标签进行类型转换，而x作为输入则进入模型的预测，并输出结果为y_pred，上下文中更新x，y_true等内容，方便后续计算Loss以及相关指标。

###### 13. LossHandler类：
损失处理器，继承自HandlerContainer，通过上下文中获取到的损失函数，将每个step的y_pred于y_true作为参数输入，得到损失结算结果，然后更新该步的损失值。注意run.loss是一个计算函数，而step.loss是一个存储的值。

###### 14. BackwardHandler类：
反向传播处理器，继承自HandlerContainer，总步数模梯度积累用于判断是否除以完整的grad_acc，剩下的步数是不是小于它，确保其记录的是这个loss对应的步数。然后loss/grad_acc， 再进行反向传播。

###### 15. OptimizerHandler类：
优化器处理器，继承自HandlerContainer，如果有优化器且处在每个梯度积累的最终步，则进行优化操作。

###### 16. MetricsHandler类：
指标处理器，继承自Handler，计算上下文中的指标们。

###### 17. AverageHandler类：
平均处理器，继承自Handler，用于处理各种计算结果的平均。

(1) average函数：用来求损失和指标的平均值并保存回上下文中。

(2) clear函数：用来重置之前求出的各种平均值。

(3) _compute_avg_loss函数：计算summary信息中的loss结果与count结果的相除结果。

(4) _compute_avg_metrics函数：计算summary信息中的各种指标的计算结果与count结果的相除结果。

###### 18. DisplayHandler类：
显示处理器，继承自Handler，用于设定终端内的显示属性，控制光标等操作。

###### 19. DatasetHandler类：
数据集处理器，继承自Handler，通过调用上下文状态的get_dataset函数，为对应的状态取出对应的数据集。

###### 20. StatusHandler类：
状态处理器，继承自Handler，设定状态并对上下文状态进行修改

###### 21. LRDecayHandler类：
学习率衰减处理器，继承自Handler，如果设置了衰减，则将调用run.lr_decay.step进行衰减操作

###### 22. BeginHandler等六个相关类：
开始、结束、步开始、步结束、轮开始、轮结束处理器，继承自Handler，是回调适配器，标志着回调的开始结束。

##### /context.py

###### 1. Context类：
上下文类，继承自Base类，贯穿于整个生命周期。有run, epoch, step, handler, custom, inner这六个MultiConst实例对象。其中当一个上下文被实例化，就会对这六个实例对象重新赋值为对应的上下文类对象。除此之外的device，model，status，dataset属性暂时为NOTHING，但是都各自具有类型。

（1）ctx_check函数：内部有一个_check函数，调用Base类里的check函数来检测传入的项是否存在，silent参数表示的是输出的信息是debug（默认不输出）还是警告。然后在_check外，进行判断，如果传入的items是由list和tuple组成的元组实例化的对象，则遍历该对象的每一个项，然后进行判断，否则，即传入的items只是个单独的值，就只需要对它本身进行检测即可。

###### 2. TempContext类：
临时上下文类，或者叫做空上下文类，继承自Base类，用于定义一个初始化的方法来迅速重置上下文。Initialize方法是一个抽象方法。

###### 3. StepContext类：
步阶上下文，继承自临时上下文类，重写initialize方法，包含x, y_pred等多个与模型训练一个step相关的属性，并初始化为NOTHING。

###### 4. EpochContext类：
轮上下文，继承自临时上下文类，重写initialize方法，包含total, current等多个与模型训练一轮相关的属性，并初始化为NOTHING。

###### 5. RunContext类：
运行上下文，继承自临时上下文类，重写initialize方法，包含train, eval, predict等多个与实际运行torch-lib的训练、评估、预测有关的属性，并初始化为对应需要的值。

###### 6. HandlerContext类：
处理器上下文，继承自临时上下文类，重写initialize方法，包含Container，EpochIteration等各式各样的处理器。

###### 7. CustomContext类：
惯常上下文，继承自临时上下文类，重写initialize方法，将类内存储的属性字典清空，并输出信息“惯常上下文已被初始化“

###### 8. InnerContext类：
内部上下文，继承自临时上下文类，重写initialize方法，将类内存储的属性字典清空，并输出信息“内部上下文已被初始化“

##### /status.py

###### 1. proxy_status：
注册一个叫做proxy_status的内容。

###### 2. Status类：
状态类，声明了一系列方法用于设置模型的模式、获取数据集、获取损失与指标等操作，在_get_avg_inner_init_item函数中，返回一个初始化的字典内容，包括了计数、损失和指标字典。

###### 3. TrainStatus和EvalStatus类：
训练状态和评估状态，都继承自Status类，分别完善了基类的空方法，对实施计算展示的get系列函数进行了定义。

###### 4. ValStatus和PredictStatus类：
验证状态和预测状态，都继承自EvalStatus类，验证状态其实就是每一轮结束后的评估状态，所以原理就如评估状态。预测状态与评估状态是一致的。

##### /__init__.py

###### 1. T=TypeVar(‘T’, bound=’Proxy’)：
用泛型，T可以被允许的类型是Proxy类以及其子类。

###### 2. DATASET：
一个类型声明，可以是DataLoader类或者DataProvider类

###### 3. Proxy类：
代理类，继承自Context类。
(1) __init__函数：先用Context的初始化函数，除此之外还会设置一下使用设备、模型。最后用链式调用训练、预测和评估的过程建立函数。
（2）train函数：激活Debug信息的输出。需要参数如下：
